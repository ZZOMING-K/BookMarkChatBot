import streamlit as st 
from gemini import get_conversation_chain
from langchain.memory import StreamlitChatMessageHistory
from langchain.callbacks import get_openai_callback
from dataloader import page_content 
from embeddings import text_split , vector_store
import os

GOOGLE_API_KEY = st.secrets["google"]["api_key"]
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

st.set_page_config(
    page_title="ë¶ë§ˆí¬ GPT",
    page_icon=":books:")

st.title("ë¶ë§ˆí¬ :orange[GPT] ğŸ“š")

if "conversation" not in st.session_state:
        st.session_state.conversation = None

if "chat_history" not in st.session_state:
        st.session_state.chat_history = None

if "processComplete" not in st.session_state:
        st.session_state.processComplete = None


if 'messages' not in st.session_state:
    st.session_state['messages'] = [{"role": "assistant", 
                                     "content": "ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë´ì£¼ì„¸ìš”!"}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

history = StreamlitChatMessageHistory(key="chat_messages")

# Chat logic
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("user"):
        st.markdown(user_input)
    
     # ë‹¤ë¥¸ í˜ì´ì§€ì—ì„œ ì €ì¥ëœ URL ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    if "url_list" in st.session_state:
        urls = list(st.session_state.url_list.url_title_mapping().values())
    else:
        st.warning("ì €ì¥ëœ URLì´ ì—†ìŠµë‹ˆë‹¤.")
        urls = []    
    
    #st.write(urls)

    splits = page_content(urls)
    
    chunks =  text_split(splits)
    
    vetorestore = vector_store(chunks)
    
    st.session_state.conversation = get_conversation_chain(vetorestore) 
    st.session_state.processComplete = True

    with st.chat_message("assistant"):
        chain = st.session_state.conversation

        with st.spinner("Thinking..."):
            result = chain({"question": user_input})
            with get_openai_callback() as cb:
                st.session_state.chat_history = result['chat_history']
            response = result['answer']
            source_documents = result['source_documents']
            
            st.session_state.messages.append({"role": "assistant", "content": response})

            st.markdown(response)
            with st.expander("ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                st.markdown(source_documents[0].metadata['source'], help = source_documents[0].page_content)